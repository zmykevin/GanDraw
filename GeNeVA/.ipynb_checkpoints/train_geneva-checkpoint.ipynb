{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zmykevin/CoDraw_Gaugan/code/GeNeVA/geneva/utils/config.py:15: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  keys = yaml.load(f)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import json # Added to initialize the setting in Jupyter Notebook-by Mingyang\n",
    "import easydict # Added to initialize the setting in Jupyter Notebook-by Mingyang\n",
    "\n",
    "from geneva.data.datasets import DATASETS\n",
    "from geneva.evaluation.evaluate import Evaluator\n",
    "from geneva.utils.config import keys, parse_config\n",
    "from geneva.utils.visualize import VisdomPlotter\n",
    "from geneva.models.models import MODELS\n",
    "from geneva.data import codraw_dataset\n",
    "from geneva.data import clevr_dataset\n",
    "from geneva.data import gandraw_dataset\n",
    "#from torch.nn import DataParallel #Added by Mingyang Zhou\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct a function to compute the evaluation metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "\n",
    "    def __init__(self, cfg):\n",
    "        img_path = os.path.join(cfg.log_path,\n",
    "                                cfg.exp_name,\n",
    "                                'train_images_*')\n",
    "        if glob.glob(img_path):\n",
    "            raise Exception('all directories with name train_images_* under '\n",
    "                            'the experiment directory need to be removed')\n",
    "        path = os.path.join(cfg.log_path, cfg.exp_name)\n",
    "\n",
    "        self.model = MODELS[cfg.gan_type](cfg)\n",
    "        #Added by Mingyang\n",
    "#         if cfg.gan_type == \"recurrent_gan_mingyang\":\n",
    "#           print(\"Wrap DataParallel Around the whole model\")\n",
    "#           self.model = DataParallel(self.model)\n",
    "\n",
    "        self.model.save_model(path, 0, 0)\n",
    "\n",
    "        if cfg.load_snapshot is not None:\n",
    "            self.model.load_model(cfg.load_snapshot)\n",
    "        shuffle = False\n",
    "        \n",
    "        self.dataset = DATASETS[cfg.dataset](\n",
    "            path=keys[cfg.dataset], cfg=cfg, img_size=cfg.img_size)\n",
    "        \n",
    "        self.dataloader = DataLoader(self.dataset,\n",
    "                                     batch_size=cfg.batch_size,\n",
    "                                     shuffle=shuffle,\n",
    "                                     num_workers=cfg.num_workers,\n",
    "                                     pin_memory=True,\n",
    "                                     drop_last=True)\n",
    "\n",
    "        if cfg.dataset in ['codraw','codrawDialog']:\n",
    "            self.dataloader.collate_fn = codraw_dataset.collate_data\n",
    "        elif cfg.dataset == 'iclevr':\n",
    "            self.dataloader.collate_fn = clevr_dataset.collate_data\n",
    "        elif cfg.dataset == \"gandraw\":\n",
    "            self.dataloader.collate_fn = gandraw_dataset.collate_data\n",
    "\n",
    "        self.visualizer = VisdomPlotter(\n",
    "            env_name=cfg.exp_name, server=cfg.vis_server)\n",
    "        self.logger = None\n",
    "\n",
    "        self.cfg = cfg\n",
    "\n",
    "    def train(self):\n",
    "        iteration_counter = 0\n",
    "        #print(\"Total number of training data: {}\".format(len(self.dataset)))\n",
    "        num_batches = len(self.dataloader)\n",
    "        total_iterations = num_batches * self.cfg.epochs\n",
    "        current_batch_time = 0 #Record the time it takes to process one batch\n",
    "        #print(\"total iteration is: {}\".format(total_iterations))\n",
    "        for epoch in range(self.cfg.epochs):\n",
    "            if cfg.dataset in ['codraw', 'gandraw']:\n",
    "                self.dataset.shuffle()\n",
    "\n",
    "            for batch in self.dataloader:\n",
    "                if iteration_counter >= 0 and iteration_counter % self.cfg.save_rate == 0:\n",
    "                    torch.cuda.empty_cache()\n",
    "                    evaluator = Evaluator.factory(self.cfg, self.visualizer,\n",
    "                                                  self.logger)\n",
    "                    evaluator.evaluate(iteration_counter)\n",
    "                    del evaluator\n",
    "                \n",
    "                \n",
    "                if  cfg.gan_type == \"recurrent_gan\":\n",
    "                    self.model.train_batch(batch,\n",
    "                                           epoch,\n",
    "                                           iteration_counter,\n",
    "                                           self.visualizer,\n",
    "                                           self.logger)\n",
    "                elif  cfg.gan_type == \"recurrent_gan_mingyang\":\n",
    "                    current_batch_start = time.time()\n",
    "                    self.model.train_batch(batch,\n",
    "                                           epoch,\n",
    "                                           iteration_counter,\n",
    "                                           self.visualizer,\n",
    "                                           self.logger,\n",
    "                                           total_iters=total_iterations,\n",
    "                                           current_batch_t=current_batch_time\n",
    "                                          )\n",
    "                    current_batch_time = time.time()-current_batch_start\n",
    "                    print(\"batch_time is: {}\".format(current_batch_time))\n",
    "                \n",
    "                iteration_counter += 1\n",
    "                return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing Initilizing the Trainer\n"
     ]
    }
   ],
   "source": [
    "config_file = \"example_args/gandraw_args.json\"\n",
    "#Load the config_file\n",
    "with open(config_file, 'r') as f:\n",
    "    cfg = json.load(f)\n",
    "#convert cfg as easydict\n",
    "cfg = easydict.EasyDict(cfg)\n",
    "cfg.load_snapshot = None\n",
    "trainer = Trainer(cfg)\n",
    "print(\"Finishing Initilizing the Trainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]/home/zmykevin/miniconda3/envs/geneva/lib/python3.6/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "100%|██████████| 2/2 [00:03<00:00,  2.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute the Evaluation Score on the Generate Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/conda-bld/pytorch_1573049304260/work/aten/src/ATen/native/cudnn/RNN.cpp:1268: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/home/zmykevin/miniconda3/envs/geneva/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/conda-bld/pytorch_1573049304260/work/aten/src/ATen/native/cudnn/RNN.cpp:1268: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1573049304260/work/aten/src/ATen/native/cudnn/RNN.cpp:1268: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1573049304260/work/aten/src/ATen/native/cudnn/RNN.cpp:1268: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1573049304260/work/aten/src/ATen/native/cudnn/RNN.cpp:1268: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1573049304260/work/aten/src/ATen/native/cudnn/RNN.cpp:1268: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "batch_time is: 13.172778129577637\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
